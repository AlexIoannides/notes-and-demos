{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0693fcf-12ed-4601-9294-f5cdeb09eef0",
   "metadata": {},
   "source": [
    "# NLP Pipelines for Beginners\n",
    "\n",
    "Basic NLP using SpaCy models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf6ca4-02b7-4d02-8534-83601808ec58",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc62755f-0c19-4f8b-afe2-5f92e037d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import List\n",
    "\n",
    "import spacy\n",
    "from spacy import Language\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens.doc import Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a34de-78a0-40f8-bd4a-7aab2df481a2",
   "metadata": {},
   "source": [
    "## Load a test Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ac5d1b-2c26-4325-8226-419a3dba285d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fidelity International acquires LGIM’s UK personal investing arm\\nBy Michael Klimes 23rd October 2020'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = \"data/fidelity_1.txt\"\n",
    "\n",
    "with open(test_file, \"r\") as file:\n",
    "    test_doc = file.read()\n",
    "    \n",
    "test_doc[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8b104e-037b-4054-bbd2-1cddf13938a6",
   "metadata": {},
   "source": [
    "## Load the SpaCy Language Model\n",
    "\n",
    "A SpaCy language model can be though of as a pipeline of text processing stages, that maps documents into tokens and their annotations (attributes of token objects). For full details, see the [SpaCy docs](https://spacy.io/api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "753c7572-4606-48b3-b69b-a6c9931bbec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "test_doc_ = nlp(test_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d6551-1705-4c8e-b784-ddbff65c42fc",
   "metadata": {},
   "source": [
    "## Sentences\n",
    "\n",
    "Documents can be processed on a sentence-by-sentence basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f67ea8f8-2976-430d-8501-f388b53cf740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 33 sentences in the document.\n"
     ]
    }
   ],
   "source": [
    "sentences = list(test_doc_.sents)\n",
    "print(f\"There are {len(sentences)} sentences in the document.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aeab98-8444-4f19-88b1-737a76cc8629",
   "metadata": {},
   "source": [
    "This is based on using a full-stop as a delimiter. We can use other tokens as sentence delimiters, by adding a new text processing stage to the SpaCy NLP pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66eba688-7fa3-41aa-babb-a01f85cc950b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence..., with..., customized, ..., delimiters.]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@Language.component(\"custom_sentence_delimiters\")\n",
    "def custom_sentence_delimiters(doc: Doc) -> Doc:\n",
    "    delimiters = [\"...\"]\n",
    "    for token in doc[:-1]:\n",
    "        if token.text in delimiters:\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"custom_sentence_delimiters\", before=\"parser\")\n",
    "\n",
    "test_text = \"This is a sentence... with... customized ... delimiters.\"\n",
    "[sent for sent in nlp(test_text).sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b33b4-1ed9-45e9-8877-062b4ba9323c",
   "metadata": {},
   "source": [
    "## Tokens\n",
    "\n",
    "After sentences are detected they are broken down into tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82628e04-29f9-4dc2-be44-ae9ecc316328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This, is, a, sentence, ..., with, ..., customized, ..., delimiters, .]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [token for token in nlp(test_text)]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9eeea8-8f1d-49d0-b974-c06b1b383b45",
   "metadata": {},
   "source": [
    "A token is an object with many [attributes](https://spacy.io/api/token#attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ee30c7-4c54-409b-881b-803d7014c88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token type = <class 'spacy.tokens.token.Token'>\n",
      "token index = 0\n"
     ]
    }
   ],
   "source": [
    "first_token = tokens[0]\n",
    "print(f\"token type = {type(first_token)}\")\n",
    "print(f\"token index = {first_token.idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629574eb-b5e8-4a7f-b1d0-a6c53f5cded3",
   "metadata": {},
   "source": [
    "Custom tokenizers can be created via `nlp,tokenizer = spacy.tokenizer.Tokenizer(...)` - [more info](https://spacy.io/api/tokenizer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a957a63-caf5-4cae-bc4d-284546fbf0b8",
   "metadata": {},
   "source": [
    "Removing stop words and punctuation using tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fc14228-4247-48aa-987d-637c03027e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sentence, customized, delimiters]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in tokens if not (token.is_stop or token.is_punct)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150dadf5-55e0-4bf7-a366-eed6a5339686",
   "metadata": {},
   "source": [
    "Tokens also contain an attribute for the lemma of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1a1478-c36f-4ddf-9013-5f31e9005483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence', 'customize', 'delimiter']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.lemma_ for token in tokens if not token.is_stop and not token.is_punct]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4586c3-b9c8-44f4-8857-4db69cef3d3b",
   "metadata": {},
   "source": [
    "### From Tokens to Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b1c4912-533a-4410-86f7-d319827e9803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fidelity', 10),\n",
       " ('investment', 9),\n",
       " ('personal', 7),\n",
       " ('investing', 7),\n",
       " ('lgim', 6),\n",
       " ('customer', 6),\n",
       " ('international', 4),\n",
       " ('uk', 4),\n",
       " ('business', 4),\n",
       " ('platform', 4)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_tokens = list(token for token in test_doc_)\n",
    "\n",
    "word_freq = Counter(\n",
    "    [token.lemma_.lower() for token in doc_tokens\n",
    "     if not token.is_stop and token.is_alpha]\n",
    ")\n",
    "word_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d209daaa-9f23-44b2-a2b0-f2f25a012959",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging\n",
    "\n",
    "All documents that have been through the SpaCy pipleine have been Part of Speech (POS) tagged, the results of which can be accessed via a token's attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e220d16a-6648-4555-98a3-5d821726079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity|NNP|PROPN|noun, proper singular|\n",
      "International|NNP|PROPN|noun, proper singular|\n",
      "acquires|VBZ|VERB|verb, 3rd person singular present|\n",
      "LGIM|NNP|PROPN|noun, proper singular|\n",
      "’s|POS|PART|possessive ending|\n"
     ]
    }
   ],
   "source": [
    "for token in doc_tokens[:5]:\n",
    "    print(f\"{token.text}|{token.tag_}|{token.pos_}|{spacy.explain(token.tag_)}|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d148b7b-e24d-49a2-9f0c-7a46888da226",
   "metadata": {},
   "source": [
    "## Rules-Based Matching\n",
    "\n",
    "You could think of this as an enhanced regex that can use token attributes, such as POS tags, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e3b845e-e8a0-446b-a778-7f7f50eb028e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Fidelity International': 3,\n",
       "         'Michael Klimes': 1,\n",
       "         'General Investment': 1,\n",
       "         'Investment Management': 1,\n",
       "         'Personal Investing': 2,\n",
       "         'Stuart Welch': 1,\n",
       "         'Cavendish Online': 1,\n",
       "         'Online Investments': 1,\n",
       "         'Investments Limited': 1,\n",
       "         'Michelle Scrimgeour': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_full_name(doc: Doc) -> List[str]:\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    patterns = [[{\"POS\": \"PROPN\"}, {\"POS\": \"PROPN\"}]]\n",
    "    matcher.add(\"FULL_NAME\", patterns)\n",
    "    return [doc[start:end].text for match_id, start, end in matcher(doc)]\n",
    "\n",
    "\n",
    "Counter(extract_full_name(test_doc_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe525d2d-bebf-433a-8b68-5741e8a4eb8f",
   "metadata": {},
   "source": [
    "## Phrase Detection\n",
    "\n",
    "Noun phrases can be automatically processed by SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8714a95-ec00-4e20-93ec-7ed5b7811ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Fidelity International,\n",
       " LGIM’s UK personal investing arm,\n",
       " Michael Klimes,\n",
       " 23rd,\n",
       " October]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_chunks = [chunk for chunk in test_doc_.noun_chunks]\n",
    "noun_chunks[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56919ac6-71b5-4558-9651-9f1ed613ca03",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fab73d56-c5de-4515-b663-c5c9ebe9ebbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity International|ORG|Companies, agencies, institutions, etc.\n",
      "LGIM|ORG|Companies, agencies, institutions, etc.\n",
      "UK|GPE|Countries, cities, states\n",
      "Michael Klimes|PERSON|People, including fictional\n",
      "Fidelity International|ORG|Companies, agencies, institutions, etc.\n",
      "Legal & General Investment Management’s|ORG|Companies, agencies, institutions, etc.\n",
      "UK|GPE|Countries, cities, states\n",
      "Fidelity’s|ORG|Companies, agencies, institutions, etc.\n",
      "UK|GPE|Countries, cities, states\n",
      "almost 300,000|CARDINAL|Numerals that do not fall under another type\n",
      "5.8bnin|MONEY|Monetary values, including unit\n",
      "Fidelity’s Personal Investing|ORG|Companies, agencies, institutions, etc.\n",
      "280,000|CARDINAL|Numerals that do not fall under another type\n",
      "20.3bn|MONEY|Monetary values, including unit\n",
      "the next 12 months|DATE|Absolute or relative dates or periods\n",
      "Fidelity|ORG|Companies, agencies, institutions, etc.\n",
      "today|DATE|Absolute or relative dates or periods\n",
      "over 3,000|CARDINAL|Numerals that do not fall under another type\n",
      "Isa, Sipp|ORG|Companies, agencies, institutions, etc.\n",
      "Fidelity’s|ORG|Companies, agencies, institutions, etc.\n",
      "daily|DATE|Absolute or relative dates or periods\n",
      "Fidelity’s|ORG|Companies, agencies, institutions, etc.\n",
      "Android|ORG|Companies, agencies, institutions, etc.\n",
      "June|DATE|Absolute or relative dates or periods\n",
      "Fidelity|ORG|Companies, agencies, institutions, etc.\n",
      "Fidelity International|ORG|Companies, agencies, institutions, etc.\n",
      "Stuart Welch|PERSON|People, including fictional\n",
      "Cavendish Online Investments Limited|ORG|Companies, agencies, institutions, etc.\n",
      "UK|GPE|Countries, cities, states\n",
      "LGIM|ORG|Companies, agencies, institutions, etc.\n",
      "Michelle Scrimgeour|PERSON|People, including fictional\n",
      "LGIM|ORG|Companies, agencies, institutions, etc.\n",
      "two|CARDINAL|Numerals that do not fall under another type\n",
      "Fidelity International’s|ORG|Companies, agencies, institutions, etc.\n",
      "LGIM|ORG|Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "for ent in test_doc_.ents:\n",
    "    print(f\"{ent.text}|{ent.label_}|{spacy.explain(ent.label_)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "9dc4f215462ea912f4965da2670482d3eef22f25452006b3bdce86b7cb4ab1a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
