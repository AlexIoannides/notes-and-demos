{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sorted-indonesian",
   "metadata": {},
   "source": [
    "# Linear Regression with SGD\n",
    "\n",
    "Exploring how one of the most basic machine learning models can be implemented using PyTorch and Stochastic Gradient Descent (SGD), from first principles. We then explore the same model using the PyTorch optimiser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-radius",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "contemporary-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, Tuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-holmes",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "invisible-freeware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10572e310>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-mileage",
   "metadata": {},
   "source": [
    "## Linear Regression with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-ballet",
   "metadata": {},
   "source": [
    "Start by creating a dataset and dataloader for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "democratic-decision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples = 400\n",
      "data[0] = (tensor([-2.]), tensor([-3.5256]))\n",
      "mini_batch[0] = [tensor([[-2.0000],\n",
      "        [-1.9900],\n",
      "        [-1.9800],\n",
      "        [-1.9700],\n",
      "        [-1.9600]]), tensor([[-3.5256],\n",
      "        [-2.7402],\n",
      "        [-2.6340],\n",
      "        [-3.5795],\n",
      "        [-2.0602]])]\n"
     ]
    }
   ],
   "source": [
    "class LinearModelData(Dataset):\n",
    "    \n",
    "    def __init__(self, b: float, w: float):\n",
    "        self.w = torch.tensor(w)\n",
    "        self.b = torch.tensor(b)\n",
    "        self.X = torch.arange(-2, 2, 0.01).view(-1, 1)\n",
    "        self.y = self.b + self.w * self.X + torch.randn(self.X.size())\n",
    "        self.len = self.y.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx: float) -> Tuple[torch.FloatTensor, torch.FloatTensor]:\n",
    "        return (self.X[idx], self.y[idx])\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.len\n",
    "    \n",
    "    \n",
    "data = LinearModelData(b=0, w=1)\n",
    "print(f'n_samples = {len(data)}')\n",
    "print(f'data[0] = {data[0]}')\n",
    "\n",
    "data_loader = DataLoader(dataset=data, batch_size=5)\n",
    "data_batches = list(data_loader)\n",
    "print(f'mini_batch[0] = {data_batches[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-rescue",
   "metadata": {},
   "source": [
    "Now define the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "departmental-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "    \"\"\"Linear regression from first principles using gradient descent.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.b = torch.tensor([torch.randn(1)], requires_grad=True)\n",
    "        self.w = torch.tensor([torch.randn(1)], requires_grad=True)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute a prediction.\"\"\"\n",
    "        y_hat = self.b + self.w * x\n",
    "        return y_hat\n",
    "\n",
    "    \n",
    "class MSELoss(torch.nn.Module):\n",
    "    \"\"\"Mean squared-error loss from first principles.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, y_hat: torch.Tensor, y: torch.Tensor):\n",
    "        \"\"\"Compute loss.\"\"\"\n",
    "        return torch.mean((y_hat - y) ** 2)\n",
    "    \n",
    "\n",
    "def train_linear_regression(\n",
    "    model: torch.nn.Module,\n",
    "    criterion: torch.nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    n_epochs: int,\n",
    "    learning_rate: float\n",
    ") -> Sequence[float]:\n",
    "    \"\"\"Train the model over multiple epochs recording the loss for each.\"\"\"\n",
    "\n",
    "    def process_batch(X: torch.Tensor, y: torch.Tensor) -> float:\n",
    "        y_hat = model.forward(X)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "\n",
    "        model.w.data -= lr * model.w.grad.data\n",
    "        model.w.grad.data.zero_()\n",
    "\n",
    "        model.b.data -= lr * model.b.grad.data\n",
    "        model.b.grad.data.zero_()\n",
    "\n",
    "        return loss.detach().numpy().tolist()\n",
    "\n",
    "    def process_epoch() -> float:\n",
    "        return [process_batch(X, y) for X, y in data_loader][-1]\n",
    "\n",
    "    lr = torch.tensor(learning_rate)\n",
    "    training_run = [process_epoch() for epoch in range(n_epochs)]\n",
    "    return training_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-restaurant",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "processed-spending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial parameters:\n",
      "\n",
      "post-training parameters:\n",
      "\n",
      "loss per-epoch:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5875461101531982,\n",
       " 1.5779359340667725,\n",
       " 1.5811569690704346,\n",
       " 1.580075740814209,\n",
       " 1.580438256263733,\n",
       " 1.5803166627883911,\n",
       " 1.5803577899932861,\n",
       " 1.58034348487854,\n",
       " 1.580348253250122,\n",
       " 1.5803463459014893,\n",
       " 1.5803474187850952,\n",
       " 1.580346941947937,\n",
       " 1.580346941947937,\n",
       " 1.5803475379943848,\n",
       " 1.580346941947937,\n",
       " 1.5803475379943848,\n",
       " 1.580346941947937,\n",
       " 1.5803475379943848,\n",
       " 1.580346941947937,\n",
       " 1.5803475379943848]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "mse_loss = MSELoss()\n",
    "print('initial parameters:')\n",
    "for k, v in lin_reg.state_dict().items():\n",
    "    print(f'  {k}: {v}')\n",
    "\n",
    "print('\\npost-training parameters:')\n",
    "per_epoch_loss = train_linear_regression(\n",
    "    lin_reg,\n",
    "    mse_loss,\n",
    "    data_loader,\n",
    "    n_epochs=20,\n",
    "    learning_rate=0.05\n",
    ")\n",
    "for k, v in lin_reg.state_dict().items():\n",
    "    print(f'  {k}: {v}')\n",
    "\n",
    "print('\\nloss per-epoch:')\n",
    "per_epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-cookie",
   "metadata": {},
   "source": [
    "Testing the model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "social-vertex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0321, grad_fn=<SqrtBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = LinearModelData(b=0, w=1)\n",
    "rmse = torch.sqrt(torch.mean((lin_reg.forward(test_data.X) - test_data.y) ** 2))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-closing",
   "metadata": {},
   "source": [
    "Which is in-line what one would expect with a noise term that is a standard Normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-kennedy",
   "metadata": {},
   "source": [
    "## Linear Regression with the PyTorch Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imported-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionPyTorch(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size: int, output_size: int):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, X) -> torch.FloatTensor:\n",
    "        \"\"\"Compute a prediction.\"\"\"\n",
    "        return self.model(X)\n",
    "\n",
    "\n",
    "def train_linear_regression_pytorch(\n",
    "    model: torch.nn.Module,\n",
    "    criterion: torch.nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    n_epochs: int,\n",
    "    learning_rate: float\n",
    ") -> Sequence[float]:\n",
    "    \"\"\"Train the model over multiple epochs recording the loss for each.\"\"\"\n",
    "\n",
    "    def process_batch(X: torch.Tensor, y: torch.Tensor) -> float:\n",
    "        y_hat = model.forward(X)\n",
    "        loss = criterion(y_hat, y)\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        return loss.detach().numpy().tolist()\n",
    "\n",
    "    def process_epoch() -> float:\n",
    "        return [process_batch(X, y) for X, y in data_loader][-1]\n",
    "\n",
    "    optimiser = torch.optim.SGD(model.parameters(), lr=0.05)\n",
    "    training_run = [process_epoch() for epoch in range(n_epochs)]\n",
    "    return training_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-terrace",
   "metadata": {},
   "source": [
    "We now training the model using `optim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cutting-shareware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5170482397079468,\n",
       " 1.601954698562622,\n",
       " 1.5731377601623535,\n",
       " 1.5827713012695312,\n",
       " 1.5795338153839111,\n",
       " 1.5806201696395874,\n",
       " 1.580255389213562,\n",
       " 1.5803780555725098,\n",
       " 1.5803368091583252,\n",
       " 1.5803507566452026,\n",
       " 1.5803462266921997,\n",
       " 1.5803475379943848,\n",
       " 1.580346941947937,\n",
       " 1.5803475379943848,\n",
       " 1.580346941947937,\n",
       " 1.580346941947937,\n",
       " 1.580346941947937,\n",
       " 1.580346941947937,\n",
       " 1.580346941947937,\n",
       " 1.580346941947937]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg_pt = LinearRegressionPyTorch(1, 1)\n",
    "mse_loss_pt = torch.nn.MSELoss()\n",
    "train_linear_regression_pytorch(\n",
    "    lin_reg_pt,\n",
    "    mse_loss_pt,\n",
    "    data_loader,\n",
    "    n_epochs=20,\n",
    "    learning_rate=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-content",
   "metadata": {},
   "source": [
    "Testing the model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deluxe-adelaide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0321, grad_fn=<SqrtBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = torch.sqrt(torch.mean((lin_reg_pt.forward(test_data.X) - test_data.y) ** 2))\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "53195f2e71dcfe3ea716e20379841f9508c7537c854fc223ac4e4b5eed7dc1d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
