{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to JAX\n",
    "\n",
    "[JAX](https://jax.readthedocs.io/en/latest/index.html) is an advanced scientific computing library for Python. At a very crude level, it's an alternative to Numpy that provides auto-differentiation and Xcellerated Linear Algebra (XLA) that can run on GPUs. Unlike Tensorflow and PyTorch, it only operates within a functional programming paradism, where all functions must be pure (enforce referential transparency). It is developed and maintained by Google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JAX as Accelerated Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JAX implements the Numpy API and more-often-than-not it can be used as a stand-in replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([1., 2., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = jnp.array([1., 2., 3., 4., 5.])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are, however, a few subtle differences. Firstly, the output is of type `DeviceArray`, which represents an array on a particular device (CPU, GPU, etc.). To convert this back to raw Numpy, use the `to_py` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.to_py()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, when a JAX function is called, the corresponding operation is dispatched to an accelerator to be computed asynchronously when possible. The returned array is therefore not necessarily ‘filled in’ as soon as the function returns. Thus, if we don’t require the result immediately, the computation won’t block Python execution. If the computation is required - e.g., when using the `block_until_ready` method, converting to a Numpy array or printing a result, then the call to the computation will be blocking. See [Asynchronous dispatch](https://jax.readthedocs.io/en/latest/async_dispatch.html#asynchronous-dispatch) in the JAX docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = jnp.dot(x, x).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiation\n",
    "\n",
    "Auto-differentiation is Jax follows a functional programming paradigm. For example, consider the following example from PyTorch,\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "x = torch.tensor(2., requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward()\n",
    "x.grad\n",
    "\n",
    "# tensor(4.)\n",
    "```\n",
    "\n",
    "This pattern is imperative and functional. In Jax this would be implemented as follows,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(4., dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def x_squared(x: jnp.DeviceArray) -> jnp.DeviceArray:\n",
    "    return x ** 2\n",
    "\n",
    "\n",
    "x_squared_dx = jax.grad(x_squared)\n",
    "x_squared_dx(jnp.array(2.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily extrapolate this example to a simple gradient descent problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 1355.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZ60lEQVR4nO3dfXRc9X3n8fdXI8l6tOUHyQ+yjZ+wsSFgXJmHhAST4JQEtg5lA2Sblp5y1mlCziZNevJAzmlStmm7pydlH5Ju1t2wSXMIhJK4QAKnmEIgpGCQscGybMDPtmTrwbYk61kz890/ZgSyYhvb0ug3M/fzOsdn5t65mvu9MHM/c3+/e3/X3B0REYmegtAFiIhIGAoAEZGIUgCIiESUAkBEJKIUACIiEVUYuoDzMWPGDF+wYEHoMkREcsqWLVva3b169PycCoAFCxZQX18fugwRkZxiZgdON19NQCIiEaUAEBGJKAWAiEhEKQBERCJKASAiElHBAsDM5pnZc2bWaGY7zOwLoWoREYmikKeBxoEvu/trZlYJbDGzTe7eGLAmEZHICBYA7n4EOJJ+ftLMdgK1gAJAIiOZdIaSSRJJJ550Eon0Y9KJp+cnkk7SnUSSU6fd8RHz3Z2kQ9JTr/s7z0lPp54Pz3dIz0st6w5O6jUcnOH3ePe5A7zzt6lt8NHT6XnD3p3vo6Z5z2VGO937jn6vU5c/43/6d9Z1Pn9z+vcZR2dZ+a2r5rJwRvl4ri07LgQzswXAlcDm07y2HlgPMH/+/IktTCLB3ekfStIzGKd3IJF6HIzTM5CgdzBO72CCvqEE/UNJ+ocS9A8l6BtM0B9PMDCUZDCRZGAoyUA88c7zoUSSgXjqcSjhDCWSDKan40knnkjt4JO6HYeMYnb6+asumpp/AWBmFcDPgC+6e9fo1919A7ABoK6uTl8XOSN3p6s/Tnv3AO0nBzjRO0RH7yAdfUOc6B2ko2eIjr5BuvrinBwY4mR/nK6+1GP8PPbEBQalRTEmFcUoKSyguLCASYWx9GNquqKkkKJYAcWx1HRRzChMTxcWpJ4XxYxYgVGUnhcrsNTjiOmYpR4L3nkOsYICCox35hWYUVAAMTMsvYwNzzcoSO9RYgWGpaeN1DKnTr+7rNnwe4CRWs4ARk3b8PLDf0N672Xv7shGLzf8/qnpd/d2o3d8I6fPtJydsvzp95xn2J+edp3v9V75JmgAmFkRqZ3/g+7+85C1SHYbjCc52tlPc2cfRzr7aO7op7mjj5auftq6B2k/OUBb9wCD8eRp/744VkBVWRFTy4qZXFpITWUJi6sLqSwppLKkiIpJqedlxYWUF8com1RIxaQYZcWFlBbFKC2OUVIUo7QoRlHMIrODkPwWLAAs9Q36AbDT3f8+VB2SPfqHEuw/1sP+9h72H+tNP/awv72XlpP9v9U8OrWsiJmTS6iunMTi6nKqKydRXTGJ6spJTC+fxNTyIqrKiplaVkRpUUw7bZFRQh4BfAD4Q2C7mW1Lz7vX3Z8MV5JMhGTSaeroY+eRLnYdPcmuo13sOnKSfcd6TtnJTy8vZsGMct6/ZDrzppZRW1XKnKpSZleVMHtKCWXFwVswRXJayLOAXuTszXOSJzp7h3jt0Am2HjjBawc7eP1QBycH4kCqDXb+tDIumVXJLVfMYUlNBQunl3PRjDImlxQFrlwkv+knlIy7Y90DvLi7nX/ffYwtB0+wu7UbSHWeXjJrMuuunMOlc6ZwyaxKls6spHySPoYiIeibJ2MWTyTZdqiD599q4/m32tje1Ik7VJUVsWr+VD6xcg6rLprKFXOrtLMXySL6NsoFGUok+fXbbTy2rZlnd7Vysj9OgcGq+VP5sxuXcv3Sai6rnUKsQK18ItlKASDnLJl0Xt1/nMdeb+bJ7Ufo6B2iqqyIj102izXLavjA4hlMKVO7vUiuUADIezrS2cePXzrAxq1NHOnsp7QoxkcvncnvXTGHD15cTXGhBpUVyUUKADmj1w6e4IEX9/FUw1HcnRuW1fD1jy/nxuU1OgVTJA/oWyynGEokearhKA+8uI9thzqoLCnk7usW8kfXXsTcqWWhyxORcaQAECA1muTGrU3cv+ktmjr6WDijnPvWXcptq+bqzB2RPKVvdsS5O8+/1cbfPrWLXUdPcsXcKdy37lJuWFZDgc7gEclrCoAIa2jq5G+e2slvdh9j/rQyvvufruTm983WmDkiEaEAiKDWk/389S938i/bmplaVsQ3/8MK/uDqi3Q2j0jEKAAi5sntR/jGxu30DCb43JrF/OmaxRpzRySiFAAR0dE7yDcf38Fj25q5Yu4UvnP7FSypqQxdlogEpACIgF+92cpXf/YGx7oH+dLapXxuzWIKY2ruEYk6BUAe6x2M81e/3MlPNh9k6cwKfnDXai6rnRK6LBHJEgqAPHWks4+7f1jPzqNdfOZDi/iztUspKYqFLktEsogCIA81NHVy949epWcgwf/749WsWVYTuiQRyUIKgDyzqbGF//LQVqaVF/PoZ6/iklmTQ5ckIllKAZAn3J0HfrOfv/plI5fXTuEf76qjprIkdFkiksUUAHkgnkjyl0808uOXD3DTpbO4/46VlBarvV9Ezk4BkOOGEknuefA1nm5s4TPXL+Krv3uJxvARkXOiAMhhyaTzlUff4OnGFv7ilhX8yXULQ5ckIjlEVwPlKHfnW0/sYOPWJv78o0u18xeR86YAyFHfefot/umlA6z/0CLuuWFJ6HJEJAcpAHLQhhf28N3ndnPn6nl8/WOXaPhmEbkgCoAc89ArB/nrJ3dx8+Wz+fat79POX0QumAIgh/zijWbu3bid65dWc//tK4npbB8RGYOgAWBmD5hZq5k1hKwjFzQ2d/GlR16n7qKpfP/Tv6Obt4jImIXei/wQuClwDVmveyDOPT95jallRfzvT/+OLvISkXERNADc/QXgeMgasp27c+/Pt3PgWA//884rmVExKXRJIpInQh8BvCczW29m9WZW39bWFrqcCffQK4d4/PVmvvzRZVy9aHrockQkj2R9ALj7Bnevc/e66urq0OVMqMbmLr71xA4+ePEMPnv94tDliEieyfoAiKrhdv+q0iLuv2OlxvcRkXGnsYCy0Mh2/5/852vU7i8iGRH6NNCHgJeAZWZ22MzuDllPtnj41VS7/5fWLuUatfuLSIYEPQJw90+FXH822tfew7ceT7X7f26NxvgRkcxRH0AWcXe+9fgOimIFfOeTV6jdX0QySgGQRZ5ubOH5t9r44o0XUzNZt3MUkcxSAGSJvsEE9z3RyLKZldz1/gWhyxGRCNBZQFniH361m6aOPn66/hqKYsplEck87WmywP72Hv7P83v5xMo5utpXRCaMAiCw4Vs7FhcWcO/Hl4cuR0QiRAEQ2KbGFn71pjp+RWTiKQAC6h9KcN8vGlk6s0IdvyIy4dQJHNA//GoPh0/08bA6fkUkAO11Ajl4rJfvP7+HdSvnaLgHEQlCARDI957bDaCOXxEJRgEQQHNHHz/fepg7V89jpjp+RSQQBUAAG17Yizt8Rjd5EZGAFAATrL17gIdfPcitV9ZSW1UauhwRiTAFwAT7wYv7GIgn+ewa/foXkbAUABOos3eIH790gI+/bzaLqitClyMiEacAmED/9NL+1L1+daMXEckCCoAJ0jMQ54Hf7OMjl9SwYs7k0OWIiCgAJspDrxzkRO8Q93xYv/5FJDsoACZA/1CCDS/s5dpF01k1f2rockREAAXAhHh0y2FaTw7wef36F5EsogDIsHgiyfef38PKeVW8f7HG/BGR7KEAyLAn3mjm8Ik+7rlhCWYWuhwRkXcoADLswZcPsqi6nI9cUhO6FBGRUygAMmhPWzf1B05wR908Cgr0619EsosCIIMeqT9ErMC4dVVt6FJERH6LAiBDhhJJfraliRuW1VBTqSGfRST7BA0AM7vJzN40s91m9rWQtYy3599so717gDtWzwtdiojIaQULADOLAd8DPgasAD5lZitC1TPeHqk/xIyKSaxZVh26FBGR0wp5BHAVsNvd97r7IPAwsC5gPeOm7eQAz+5q5bZVtbrZu4hkrZB7p1rg0Ijpw+l5pzCz9WZWb2b1bW1tE1bcWGzceph40vlk3dzQpYiInFHW/zx19w3uXufuddXV2d+c4u48Un+YVfOrWFJTGbocEZEzChkATcDIHtK56Xk5beuhDna3dqvzV0SyXsgAeBW42MwWmlkxcCfweMB6xsU/1x+itCjGzZfPCV2KiMhZFYZasbvHzezzwL8CMeABd98Rqp7x0DsY54nXj3Dz5bOpmBTsP62IyDkJupdy9yeBJ0PWMJ6e2n6U7oE4t9ep+UdEsl/WdwLnkp/WH2LhjHJWL9BNX0Qk+ykAxsm+9h5e2XecT9bN1bDPIpITFADj5NEthygwuG2Vzv0XkdygABgH7s4Trx/huourmTlZA7+JSG5QAIyDt1u7OXi8l9+9dGboUkREzpkCYBxsamwB4MblCgARyR0KgHHwdGMLV8yrUvOPiOQUBcAYtXb18/qhDtYu1z1/RSS3KADG6JmdrQCsXTErcCUiIudHATBGz+xsYd60UpbOrAhdiojIeVEAjEHPQJwXd7ezdvksXfwlIjlHATAGv367ncF4khtXqP1fRHKPAmAMNjW2MKW0iNULpoUuRUTkvCkALlA8keTZXS3csKxa9/0VkZykPdcFeu1gByd6h3T2j4jkLAXABdrUeJSimPGhpTNClyIickEUABfA3dnU2MK1i2dQWVIUuhwRkQuiALgAe9q62X+sV1f/ikhOUwBcgKeHB39bocHfRCR3KQAuwDONLVxWO5nZU0pDlyIicsHeMwDMbMVp5q3JRDG5oO3kAFsPdbB2uc7+EZHcdi5HAI+Y2VctpdTM/hfwN5kuLFs9u6sFd1ir5h8RyXHnEgBXA/OAfwdeBZqBD2SyqGy2qbGF2qpSls+uDF2KiMiYnEsADAF9QClQAuxz92RGq8pSA/EEL+5u5yPLazT4m4jkvHMJgFdJBcBq4IPAp8zsnzNaVZbafriT/qEk71+si79EJPcVnsMyd7t7ffr5EWCdmf1hBmvKWpv3HQfgqoUa/E1Ect97HgGM2PmPnPfjzJST3V7ee4ylMyuYVl4cuhQRkTELch2AmX3SzHaYWdLM6kLUcL6GEkm2HDjB1Qunhy5FRGRchLoQrAH4feCFQOs/bw1NnfQOJrh6kZp/RCQ/nEsfwLhz951ATp1Jo/Z/Eck3WT8UhJmtN7N6M6tva2sLVscr+46zqLqcmsqSYDWIiIynjAWAmT1jZg2n+bfufN7H3Te4e52711VXV2eq3LNKJJ1X9x1X+7+I5JWMNQG5+42Zeu+JtvNIFycH4lyt5h8RySNZ3wSUDV7eewxAHcAikldCnQZ6q5kdBq4Ffmlm/xqijnO1ed9x5k8r0/DPIpJXQp0FtBHYGGLd5yuZdF7df5y1yzX6p4jkFzUBvYe3Wk/S0TvE1YvUASwi+UUB8B42702d/68OYBHJNwqA97B53zFqq0qZN60sdCkiIuNKAXAW7s4r+47r6l8RyUsKgLPY09ZNe/egmn9EJC8pAM5iePwfdQCLSD5SAJzF5r3HqamcxILpav8XkfyjADgDd2fzvmNcvWh6To1aKiJyrhQAZ3DgWC8tXQNq/xeRvKUAOIPN+9Lj/ygARCRPKQDOYPPe40wvL2ZJTUXoUkREMkIBcAab0+f/q/1fRPKVAuA0mjr6aOroU/OPiOQ1BcBpbD/cAcCV86eGLUREJIMUAKexvamTWIGxbFZl6FJERDJGAXAaDU1dXFxTQUlRLHQpIiIZowAYxd1paOrkfbVTQpciIpJRCoBRjnb1c6xnkMsUACKS5xQAozQ0dQFwWe3kwJWIiGSWAmCUhqZOCgyWz1YAiEh+UwCMsqO5k8XVFZQVF4YuRUQkoxQAo2xv6lT7v4hEggJghNaT/bR0DXDpHDX/iEj+UwCMsKM51QGsU0BFJAoUACM0HO4EYIWOAEQkAhQAIzQ0d7JwRjmVJUWhSxERyTgFwAgNTV3qABaRyAgSAGb2d2a2y8zeMLONZlYVoo6RTvQM0tTRx2Vq/hGRiAh1BLAJuMzdLwfeAr4eqI53NDSn2v91BCAiUREkANz9aXePpydfBuaGqGOk4SEgdAqoiERFNvQB/Anw1JleNLP1ZlZvZvVtbW0ZK6KhuZN500qpKivO2DpERLJJxsY7MLNngFmneekb7v5YeplvAHHgwTO9j7tvADYA1NXVeQZKBVJjAF02R80/IhIdGQsAd7/xbK+b2R8DtwAfcfeM7djPRWffEAeO9XJ73byQZYiITKggI56Z2U3AV4Dr3b03RA0jNTYPDwGtIwARiY5QfQDfBSqBTWa2zcy+H6gOIDUCKKgDWESiJcgRgLsvCbHeM9ne1MnsKSXMqJgUuhQRkQmTDWcBBdfQ1Mml6gAWkYiJfAD0DMTZ296jEUBFJHIiHwCNR7pw1z2ARSR6Ih8ADU0aAkJEokkB0NRFdeUkZk4uCV2KiMiEinwA7Gju1AigIhJJkQ6A/qEEb7d2q/lHRCIp0gGw80gXiaTrFFARiaRIB0DjEQ0BLSLRFekA2NPaQ2lRjNqq0tCliIhMuGgHQFs3i6rLKSiw0KWIiEy4yAfAkpqK0GWIiAQR2QDoG0zQ1NHH4moFgIhEU2QDYG97N+4oAEQksiIbAHvaegBYXFMeuBIRkTCiGwCt3RQYLJiuABCRaIpuALR1M29aGSVFsdCliIgEEdkA2N3arfZ/EYm0SAZAIunsa+9hcbWaf0QkuiIZAM0dfQzEkzoCEJFIi2QA7G7rBmCxLgITkQiLZADsaU0FwBIdAYhIhEUzANq6mVZezNTy4tCliIgEE80AaFUHsIhINAOgTaeAiohELgBO9AxyrGdQo4CKSORFLgD2tqfPANIRgIhEXJAAMLP/amZvmNk2M3vazOZM1Lp3tyoAREQg3BHA37n75e6+EvgF8BcTteI9bT0UFxZQO1W3gRSRaAsSAO7eNWKyHPCJWvee1m4WzSgnpttAikjEFYZasZl9G/gjoBO44SzLrQfWA8yfP3/M693T1s2ltVPG/D4iIrkuY0cAZvaMmTWc5t86AHf/hrvPAx4EPn+m93H3De5e5+511dXVY6ppIJ7g4PFetf+LiJDBIwB3v/EcF30QeBL4ZqZqGba/vZeko4vAREQIdxbQxSMm1wG7JmK9e9p0BpCIyLBQfQB/a2bLgCRwAPjTiVjp8CBwi3QEICISJgDc/bYQ693T1k1tVSllxcH6vkVEskakrgTe3datewCIiKRFJgCSSdcooCIiI0QmAI529dM3lFAHsIhIWmQCQGcAiYicKjoBMHwbSPUBiIgAEQqA3W3dTC4pZEaFbgMpIgIRCoA9rT0srqnATIPAiYhAlAJAt4EUETlFJAKgq3+I1pMDav8XERkhEgGwt60H0BlAIiIjRSIA3r0NpC4CExEZFokA2NPWTVHMmDetLHQpIiJZIxIBsGB6Gb9/5VyKYpHYXBGRcxKJYTHvWD2fO1aP/XaSIiL5RD+JRUQiSgEgIhJRCgARkYhSAIiIRJQCQEQkohQAIiIRpQAQEYkoBYCISESZu4eu4ZyZWRtw4AL/fAbQPo7l5Aptd/REddu13Wd2kbtXj56ZUwEwFmZW7+51oeuYaNru6Inqtmu7z5+agEREIkoBICISUVEKgA2hCwhE2x09Ud12bfd5ikwfgIiInCpKRwAiIjKCAkBEJKIiEQBmdpOZvWlmu83sa6HryRQze8DMWs2sYcS8aWa2yczeTj9ODVljJpjZPDN7zswazWyHmX0hPT+vt93MSszsFTN7Pb3df5mev9DMNqc/7z81s+LQtWaCmcXMbKuZ/SI9nffbbWb7zWy7mW0zs/r0vAv+nOd9AJhZDPge8DFgBfApM1sRtqqM+SFw06h5XwP+zd0vBv4tPZ1v4sCX3X0FcA1wT/r/cb5v+wDwYXe/AlgJ3GRm1wD/Dbjf3ZcAJ4C7w5WYUV8Ado6Yjsp23+DuK0ec+3/Bn/O8DwDgKmC3u+9190HgYWBd4Joywt1fAI6Pmr0O+FH6+Y+AT0xkTRPB3Y+4+2vp5ydJ7RRqyfNt95Tu9GRR+p8DHwYeTc/Pu+0GMLO5wM3A/01PGxHY7jO44M95FAKgFjg0Yvpwel5UzHT3I+nnR4GZIYvJNDNbAFwJbCYC255uBtkGtAKbgD1Ah7vH04vk6+f9vwNfAZLp6elEY7sdeNrMtpjZ+vS8C/6cR+Km8JLi7m5meXver5lVAD8DvujuXakfhSn5uu3ungBWmlkVsBG4JGxFmWdmtwCt7r7FzNYELmeiXefuTWZWA2wys10jXzzfz3kUjgCagHkjpuem50VFi5nNBkg/tgauJyPMrIjUzv9Bd/95enYkth3A3TuA54BrgSozG/5xl4+f9w8Av2dm+0k16X4Y+B/k/3bj7k3px1ZSgX8VY/icRyEAXgUuTp8hUAzcCTweuKaJ9DhwV/r5XcBjAWvJiHT77w+Ane7+9yNeyuttN7Pq9C9/zKwUWEuq/+M54D+mF8u77Xb3r7v7XHdfQOr7/Ky7/wF5vt1mVm5mlcPPgY8CDYzhcx6JK4HN7OOk2gxjwAPu/u2wFWWGmT0ErCE1PGwL8E3gX4BHgPmkhtK+3d1HdxTnNDO7Dvg1sJ1324TvJdUPkLfbbmaXk+r0i5H6MfeIu99nZotI/TKeBmwFPu3uA+EqzZx0E9Cfu/st+b7d6e3bmJ4sBH7i7t82s+lc4Oc8EgEgIiK/LQpNQCIichoKABGRiFIAiIhElAJARCSiFAAiIhGlABARiSgFgIhIRCkARMbAzBaY2U4z+8f0mPxPp6/KFcl6CgCRsbsY+J67Xwp0ALeFLUfk3CgARMZun7tvSz/fAiwIV4rIuVMAiIzdyPFmEmiYdckRCgARkYhSAIiIRJRGAxURiSgdAYiIRJQCQEQkohQAIiIRpQAQEYkoBYCISEQpAEREIkoBICISUf8fVWRi2K4eze0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f(x: jnp.DeviceArray) -> jnp.DeviceArray:\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "\n",
    "n_iterations = 50\n",
    "eta = 0.1\n",
    "\n",
    "x = jnp.array(-3.5)\n",
    "x_hist: List[Tuple[int, float]] = []\n",
    "\n",
    "for n in tqdm(range(n_iterations)):\n",
    "    x_hist.append((n, x.tolist()))\n",
    "    x -= eta *jax.grad(f)(x)\n",
    "\n",
    "print(f\"x = {x:.2f}\")\n",
    "_ = sns.lineplot(y=\"x\", x=\"n\", data=pd.DataFrame(x_hist, columns=[\"n\", \"x\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is simpler than the PyTorch equivalent,\n",
    "\n",
    "```python\n",
    "def f(x: torch.Tensor) -> torch.Tensor:\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "\n",
    "n_iterations = 50\n",
    "eta = 0.1\n",
    "\n",
    "x = torch.tensor([-3.5], requires_grad=True)\n",
    "x_hist: List[Tuple[int, float]] = []\n",
    "\n",
    "for n in tqdm(range(n_iterations)):\n",
    "    x_hist.append((n, x.detach().numpy()[0]))\n",
    "    f(x).backward()\n",
    "    x.data -= eta * x.grad\n",
    "    x.grad.zero_()\n",
    "\n",
    "print(f\"x = {x.detach().numpy()[0]:.2f}\")\n",
    "_ = sns.lineplot(y=\"x\", x=\"n\", data=pd.DataFrame(x_hist, columns=[\"n\", \"x\"]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extended this to more complex vector-valued functions, where the `grad` operator will behave like the $\\nabla$ operator in formal calculus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum-of-squares = 55.0\n",
      "d sum-of-squares / dx = [ 2.  4.  6.  8. 10.]\n"
     ]
    }
   ],
   "source": [
    "def sum_of_squares(x: jnp.DeviceArray) -> jnp.DeviceArray:\n",
    "  return jnp.sum(x**2)\n",
    "\n",
    "\n",
    "sum_of_squares_dx = jax.grad(sum_of_squares)\n",
    "\n",
    "x = jnp.array([1., 2., 3., 4., 5.])\n",
    "print(f\"sum-of-squares = {sum_of_squares(x)}\")\n",
    "print(f\"d sum-of-squares / dx = {sum_of_squares_dx(x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the `grad` operator will only compute derivatives relative to a function's first argument. To extend this to other arguments we use `argnums`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum-of-squared-errors = 0.5500001907348633\n",
      "d sum-of-squared-errors / dx = [-0.20000005 -0.4000001  -0.6000004  -0.8000002  -1.        ]\n",
      "d sum-of-squared-errors / dy = [0.20000005 0.4000001  0.6000004  0.8000002  1.        ]\n"
     ]
    }
   ],
   "source": [
    "def sum_of_squared_errors(x: jnp.DeviceArray, y: jnp.DeviceArray) -> jnp.DeviceArray:\n",
    "    return jnp.sum((x - y) ** 2)\n",
    "\n",
    "sum_of_squared_errors_dx = jax.grad(sum_of_squared_errors, argnums=(0, 1))\n",
    "\n",
    "x = jnp.array([1., 2., 3., 4., 5.])\n",
    "print(f\"sum-of-squared-errors = {sum_of_squared_errors(x, x*1.1)}\")\n",
    "print(f\"d sum-of-squared-errors / dx = {sum_of_squared_errors_dx(x, x*1.1)[0]}\")\n",
    "print(f\"d sum-of-squared-errors / dy = {sum_of_squared_errors_dx(x, x*1.1)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9dc4f215462ea912f4965da2670482d3eef22f25452006b3bdce86b7cb4ab1a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
